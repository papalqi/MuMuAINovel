"""
è®¾ç½®ç®¡ç† API
"""
from fastapi import APIRouter, HTTPException, Request, Depends
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select
from typing import Dict, Any, List, Optional
from pathlib import Path
from pydantic import BaseModel
from datetime import datetime
import httpx
import json
import time

from app.database import get_db
from app.models.settings import Settings
from app.schemas.settings import (
    SettingsCreate, SettingsUpdate, SettingsResponse,
    APIKeyPreset, APIKeyPresetConfig, PresetCreateRequest,
    PresetUpdateRequest, PresetResponse, PresetListResponse
)
from app.user_manager import User
from app.logger import get_logger
from app.config import settings as app_settings, PROJECT_ROOT
from app.services.ai_service import AIService, create_user_ai_service, create_user_ai_service_with_mcp

logger = get_logger(__name__)

router = APIRouter(prefix="/settings", tags=["è®¾ç½®ç®¡ç†"])

# ==================== AI è·¯ç”±ï¼ˆæŒ‰ä»»åŠ¡é€‰æ‹©ä¸åŒæ¨¡å‹/Providerï¼‰ ====================
#
# è®¾è®¡ç›®æ ‡ï¼š
# - å…è®¸ç”¨æˆ·åœ¨å‰ç«¯è®¾ç½®â€œä¸åŒ AI è¯·æ±‚ç±»å‹ä½¿ç”¨ä¸åŒ API é¢„è®¾ï¼ˆprovider/key/base_url/modelï¼‰â€
# - è·¯ç”±ä¿¡æ¯å­˜å‚¨åœ¨ settings.preferences(JSON) ä¸­ï¼Œé¿å…æ–°å¢æ•°æ®åº“å­—æ®µ
# - åç«¯é€šè¿‡ task_key è§£æè·¯ç”±ï¼ŒåŠ¨æ€åˆ›å»ºå¯¹åº”çš„ AIServiceï¼ˆä»è€Œæ”¯æŒè·¨ provider åˆ†æµä¸”ä½¿ç”¨ä¸åŒ keyï¼‰
#

AI_ROUTE_VERSION = "1.0"

# task_key çº¦å®šï¼šåªç”¨äºâ€œè·¯ç”±é€‰æ‹©â€ï¼Œä¸ç›´æ¥æš´éœ²ä¸ºä¸šåŠ¡æ¦‚å¿µã€‚
# å‰ç«¯ä½¿ç”¨è¿™äº› key æ˜¾ç¤ºé…ç½®é¡¹ï¼›åç«¯åœ¨å„ API è°ƒç”¨ç‚¹é€‰æ‹©å¯¹åº” keyã€‚
AI_ROUTE_TASKS: list[dict[str, str]] = [
    {"key": "wizard_world_building", "label": "å‘å¯¼ï¼šä¸–ç•Œè§‚ç”Ÿæˆ", "category": "å‘å¯¼"},
    {"key": "inspiration_options", "label": "çµæ„Ÿæ¨¡å¼ï¼šç”Ÿæˆé€‰é¡¹", "category": "çµæ„Ÿ"},
    {"key": "outline_generate", "label": "å¤§çº²ï¼šç”Ÿæˆ/ç»­å†™", "category": "å¤§çº²"},
    {"key": "outline_expand", "label": "å¤§çº²ï¼šå±•å¼€ç« èŠ‚è§„åˆ’", "category": "å¤§çº²"},
    {"key": "chapter_generate", "label": "ç« èŠ‚ï¼šç”Ÿæˆæ­£æ–‡", "category": "ç« èŠ‚"},
    {"key": "chapter_regenerate", "label": "ç« èŠ‚ï¼šé‡å†™/å†ç”Ÿæˆ", "category": "ç« èŠ‚"},
    {"key": "chapter_analysis", "label": "ç« èŠ‚ï¼šå‰§æƒ…åˆ†æ/ä¼ç¬”æå–", "category": "ç« èŠ‚"},
    {"key": "polish", "label": "æ–‡æœ¬ï¼šå»å‘³/æ¶¦è‰²", "category": "æ–‡æœ¬"},
    {"key": "character_generate", "label": "è®¾å®šï¼šç”Ÿæˆè§’è‰²", "category": "è®¾å®š"},
    {"key": "organization_generate", "label": "è®¾å®šï¼šç”Ÿæˆç»„ç»‡", "category": "è®¾å®š"},
    {"key": "career_generate", "label": "è®¾å®šï¼šç”Ÿæˆ/è¡¥å…¨èŒä¸š", "category": "è®¾å®š"},
]


class AIRouteTask(BaseModel):
    key: str
    label: str
    category: str


class AIRoutesResponse(BaseModel):
    version: str = AI_ROUTE_VERSION
    routes: Dict[str, Optional[str]]  # task_key -> preset_id (None è¡¨ç¤ºä½¿ç”¨å½“å‰é…ç½®)
    tasks: List[AIRouteTask]


class AIRoutesUpdateRequest(BaseModel):
    routes: Dict[str, Optional[str]]


# ==================== å‘é‡æ£€ç´¢é…ç½®ï¼ˆEmbedding / Rerankï¼‰ ====================
#
# è®¾è®¡ç›®æ ‡ï¼š
# - å…è®¸ç”¨æˆ·åœ¨å‰ç«¯ Settings ä¸­é…ç½®ï¼š
#   1) æœ¬åœ° embeddingï¼ˆç°æœ‰ sentence-transformersï¼‰ æˆ– è¿œç«¯ embeddingï¼ˆOpenAI å…¼å®¹æ¥å£ï¼‰
#   2) å¯é€‰çš„è¿œç«¯ rerankï¼ˆCohere å…¼å®¹æ¥å£ï¼‰
# - é…ç½®å­˜å‚¨åœ¨ settings.preferences(JSON) ä¸­çš„ retrieval å­—æ®µï¼Œé¿å…æ•°æ®åº“æ”¹åŠ¨
#

RETRIEVAL_CONFIG_VERSION = "1.0"


class RemoteEmbeddingConfig(BaseModel):
    """è¿œç«¯ Embedding é…ç½®ï¼ˆOpenAI å…¼å®¹ï¼š/v1/embeddingsï¼‰ã€‚"""

    # å…è®¸å­—æ®µååŒ…å« `model_` ç­‰å—ä¿æŠ¤å‰ç¼€
    model_config = {"protected_namespaces": ()}

    provider: str = "openai_compatible"
    api_key: Optional[str] = None
    api_base_url: Optional[str] = None  # ä¾‹å¦‚ï¼šhttps://api.openai.com/v1
    model: Optional[str] = None  # ä¾‹å¦‚ï¼štext-embedding-3-small / Qwen3-Embedding-8B
    timeout_s: int = 60


class EmbeddingConfig(BaseModel):
    """Embedding é…ç½®ã€‚"""

    model_config = {"protected_namespaces": ()}

    backend: str = "local"  # local | remote
    remote: RemoteEmbeddingConfig = RemoteEmbeddingConfig()


class RemoteRerankConfig(BaseModel):
    """è¿œç«¯ Rerank é…ç½®ï¼ˆCohere å…¼å®¹ï¼š/v1/rerankï¼‰ã€‚"""

    model_config = {"protected_namespaces": ()}

    provider: str = "cohere_compatible"
    api_key: Optional[str] = None
    api_base_url: Optional[str] = None  # ä¾‹å¦‚ï¼šhttps://api.cohere.ai/v1
    model: Optional[str] = None
    timeout_s: int = 60
    top_k: int = 30  # å‘é‡å¬å›å€™é€‰æ•°é‡
    top_n: int = 10  # rerank åè¿”å›æ•°é‡
    min_score: Optional[float] = None  # å¯é€‰ï¼šè¿‡æ»¤è¿‡ä½åˆ†


class RerankConfig(BaseModel):
    model_config = {"protected_namespaces": ()}

    enabled: bool = False
    remote: RemoteRerankConfig = RemoteRerankConfig()


class RetrievalConfigResponse(BaseModel):
    """æ£€ç´¢é…ç½®å“åº”ã€‚"""

    model_config = {"protected_namespaces": ()}

    version: str = RETRIEVAL_CONFIG_VERSION
    embedding: EmbeddingConfig = EmbeddingConfig()
    rerank: RerankConfig = RerankConfig()


class RetrievalConfigUpdateRequest(BaseModel):
    """æ£€ç´¢é…ç½®æ›´æ–°è¯·æ±‚ã€‚"""

    model_config = {"protected_namespaces": ()}

    embedding: EmbeddingConfig
    rerank: RerankConfig


class EmbeddingTestRequest(BaseModel):
    """Embedding å¯ç”¨æ€§æ£€æµ‹è¯·æ±‚ï¼ˆä¸è½åº“ï¼Œä»…ç”¨äº UI æ£€æµ‹æŒ‰é’®ï¼‰ã€‚"""

    model_config = {"protected_namespaces": ()}

    embedding: EmbeddingConfig


class EmbeddingTestResponse(BaseModel):
    """Embedding å¯ç”¨æ€§æ£€æµ‹å“åº”ã€‚"""

    model_config = {"protected_namespaces": ()}

    success: bool
    message: str
    backend: str
    response_time_ms: Optional[float] = None
    details: Optional[Dict[str, Any]] = None
    error: Optional[str] = None
    error_type: Optional[str] = None
    suggestions: Optional[List[str]] = None


class RerankTestRequest(BaseModel):
    """Rerank å¯ç”¨æ€§æ£€æµ‹è¯·æ±‚ï¼ˆä¸è½åº“ï¼Œä»…ç”¨äº UI æ£€æµ‹æŒ‰é’®ï¼‰ã€‚"""

    model_config = {"protected_namespaces": ()}

    rerank: RerankConfig


class RerankTestResponse(BaseModel):
    """Rerank å¯ç”¨æ€§æ£€æµ‹å“åº”ã€‚"""

    model_config = {"protected_namespaces": ()}

    success: bool
    enabled: bool
    message: str
    response_time_ms: Optional[float] = None
    details: Optional[Dict[str, Any]] = None
    error: Optional[str] = None
    error_type: Optional[str] = None
    suggestions: Optional[List[str]] = None


def _safe_load_preferences(preferences: Optional[str]) -> Dict[str, Any]:
    if not preferences:
        return {}
    try:
        raw = json.loads(preferences)
        return raw if isinstance(raw, dict) else {}
    except json.JSONDecodeError:
        return {}


def _get_presets_from_preferences(prefs: Dict[str, Any]) -> List[Dict[str, Any]]:
    api_presets = prefs.get("api_presets") or {}
    presets = api_presets.get("presets") or []
    return presets if isinstance(presets, list) else []


def _get_ai_routes_from_preferences(prefs: Dict[str, Any]) -> Dict[str, Optional[str]]:
    ai_routes = prefs.get("ai_routes") or {}
    routes = ai_routes.get("routes") if isinstance(ai_routes, dict) else None
    if not isinstance(routes, dict):
        return {}

    # åªä¿ç•™ str/Noneï¼Œé¿å…è„æ•°æ®
    cleaned: Dict[str, Optional[str]] = {}
    for k, v in routes.items():
        if v is None:
            cleaned[str(k)] = None
        elif isinstance(v, str) and v.strip():
            cleaned[str(k)] = v.strip()
        else:
            cleaned[str(k)] = None
    return cleaned


def _upsert_ai_routes_to_preferences(
    prefs: Dict[str, Any],
    routes: Dict[str, Optional[str]],
) -> Dict[str, Any]:
    prefs = dict(prefs or {})
    prefs["ai_routes"] = {
        "version": AI_ROUTE_VERSION,
        "updated_at": datetime.now().isoformat(),
        "routes": routes,
    }
    return prefs


def _get_retrieval_from_preferences(prefs: Dict[str, Any]) -> Dict[str, Any]:
    retrieval = prefs.get("retrieval") if isinstance(prefs, dict) else None
    return retrieval if isinstance(retrieval, dict) else {}


def _upsert_retrieval_to_preferences(
    prefs: Dict[str, Any],
    retrieval_cfg: Dict[str, Any],
) -> Dict[str, Any]:
    prefs = dict(prefs or {})
    cfg = dict(retrieval_cfg or {})
    cfg["version"] = RETRIEVAL_CONFIG_VERSION
    prefs["retrieval"] = cfg
    return prefs


def _resolve_preset_config(
    *,
    prefs: Dict[str, Any],
    preset_id: str,
) -> Optional[Dict[str, Any]]:
    if not preset_id:
        return None
    for preset in _get_presets_from_preferences(prefs):
        if str(preset.get("id")) == preset_id:
            cfg = preset.get("config")
            return cfg if isinstance(cfg, dict) else None
    return None


async def create_user_ai_service_for_task(
    *,
    user_id: str,
    db: AsyncSession,
    task_key: str,
    request_enable_mcp: Optional[bool] = None,
) -> AIService:
    """æ ¹æ® task_key è·¯ç”±åˆ›å»ºå¯¹åº” AIServiceï¼ˆæ”¯æŒè·¨ provider + ä¸åŒ keyï¼‰ã€‚

    è·¯ç”±ä¼˜å…ˆçº§ï¼š
    1) preferences.ai_routes.routes[task_key] æŒ‡å‘çš„ preset config
    2) å›é€€åˆ° Settings ä¸»å­—æ®µï¼ˆå½“å‰é…ç½®ï¼‰
    """
    from app.models.mcp_plugin import MCPPlugin

    settings = await get_user_settings(user_id, db)
    prefs = _safe_load_preferences(settings.preferences)
    routes = _get_ai_routes_from_preferences(prefs)

    preset_id = routes.get(task_key)
    preset_cfg = _resolve_preset_config(prefs=prefs, preset_id=preset_id) if preset_id else None

    # MCP å¯ç”¨é€»è¾‘ï¼šä¸ get_user_ai_service ä¿æŒä¸€è‡´ï¼Œå†å åŠ  request_enable_mcpï¼ˆå¦‚ä¼ å…¥ï¼‰
    mcp_result = await db.execute(select(MCPPlugin).where(MCPPlugin.user_id == user_id))
    mcp_plugins = mcp_result.scalars().all()
    enable_mcp_by_plugins = any(plugin.enabled for plugin in mcp_plugins) if mcp_plugins else False
    enable_mcp = enable_mcp_by_plugins
    if request_enable_mcp is not None:
        enable_mcp = enable_mcp and bool(request_enable_mcp)

    if preset_cfg:
        # æ•°å€¼ç±»å‹ï¼ˆä¾‹å¦‚ temperature=0.0ï¼‰ä¸èƒ½ç”¨ `or` åˆå¹¶ï¼Œå¦åˆ™ 0.0 ä¼šè¢«è¯¯åˆ¤ä¸ºâ€œæœªè®¾ç½®â€
        resolved_temperature = preset_cfg.get("temperature")
        if resolved_temperature is None:
            resolved_temperature = settings.temperature if settings.temperature is not None else app_settings.default_temperature

        resolved_max_tokens = preset_cfg.get("max_tokens")
        if resolved_max_tokens is None:
            resolved_max_tokens = settings.max_tokens if settings.max_tokens is not None else app_settings.default_max_tokens

        return create_user_ai_service_with_mcp(
            api_provider=str(preset_cfg.get("api_provider") or settings.api_provider),
            api_key=str(preset_cfg.get("api_key") or settings.api_key or ""),
            api_base_url=str(preset_cfg.get("api_base_url") or settings.api_base_url or ""),
            model_name=str(preset_cfg.get("llm_model") or settings.llm_model),
            temperature=float(resolved_temperature),
            max_tokens=int(resolved_max_tokens),
            user_id=user_id,
            db_session=db,
            system_prompt=settings.system_prompt,
            enable_mcp=enable_mcp,
        )

    # fallbackï¼šå½“å‰é…ç½®
    return create_user_ai_service_with_mcp(
        api_provider=settings.api_provider,
        api_key=settings.api_key,
        api_base_url=settings.api_base_url or "",
        model_name=settings.llm_model,
        temperature=settings.temperature,
        max_tokens=settings.max_tokens,
        user_id=user_id,
        db_session=db,
        system_prompt=settings.system_prompt,
        enable_mcp=enable_mcp,
    )


def read_env_defaults() -> Dict[str, Any]:
    """ä».envæ–‡ä»¶è¯»å–é»˜è®¤é…ç½®ï¼ˆä»…è¯»å–ï¼Œä¸ä¿®æ”¹ï¼‰"""
    return {
        "api_provider": app_settings.default_ai_provider,
        "api_key": app_settings.openai_api_key or app_settings.anthropic_api_key or "",
        "api_base_url": app_settings.openai_base_url or app_settings.anthropic_base_url or "",
        "llm_model": app_settings.default_model,
        "temperature": app_settings.default_temperature,
        "max_tokens": app_settings.default_max_tokens,
    }


def require_login(request: Request):
    """ä¾èµ–ï¼šè¦æ±‚ç”¨æˆ·å·²ç™»å½•"""
    if not hasattr(request.state, "user") or not request.state.user:
        raise HTTPException(status_code=401, detail="éœ€è¦ç™»å½•")
    return request.state.user


async def get_user_ai_service(
    user: User = Depends(require_login),
    db: AsyncSession = Depends(get_db)
) -> AIService:
    """
    ä¾èµ–ï¼šè·å–å½“å‰ç”¨æˆ·çš„AIæœåŠ¡å®ä¾‹ï¼ˆæ”¯æŒMCPå·¥å…·è‡ªåŠ¨åŠ è½½ï¼‰
    
    ä»æ•°æ®åº“è¯»å–ç”¨æˆ·è®¾ç½®å¹¶åˆ›å»ºå¯¹åº”çš„AIæœåŠ¡ã€‚
    è‡ªåŠ¨ä¼ é€’ user_id å’Œ db_sessionï¼Œä½¿å¾— AIService èƒ½å¤ŸåŠ è½½ç”¨æˆ·é…ç½®çš„MCPå·¥å…·ã€‚
    æ ¹æ®ç”¨æˆ·çš„æ‰€æœ‰MCPæ’ä»¶çŠ¶æ€å†³å®šæ˜¯å¦å¯ç”¨MCPï¼šå¦‚æœæœ‰å¯ç”¨çš„æ’ä»¶åˆ™å¯ç”¨ï¼Œå¦åˆ™ç¦ç”¨ã€‚
    """
    from app.models.mcp_plugin import MCPPlugin
    
    result = await db.execute(
        select(Settings).where(Settings.user_id == user.user_id)
    )
    settings = result.scalar_one_or_none()
    
    if not settings:
        # å¦‚æœç”¨æˆ·æ²¡æœ‰è®¾ç½®ï¼Œä».envè¯»å–å¹¶ä¿å­˜
        env_defaults = read_env_defaults()
        settings = Settings(
            user_id=user.user_id,
            **env_defaults
        )
        db.add(settings)
        await db.commit()
        await db.refresh(settings)
        logger.info(f"ç”¨æˆ· {user.user_id} é¦–æ¬¡ä½¿ç”¨AIæœåŠ¡ï¼Œå·²ä».envåŒæ­¥è®¾ç½®åˆ°æ•°æ®åº“")
    
    # æŸ¥è¯¢ç”¨æˆ·çš„æ‰€æœ‰MCPæ’ä»¶çŠ¶æ€
    mcp_result = await db.execute(
        select(MCPPlugin).where(MCPPlugin.user_id == user.user_id)
    )
    mcp_plugins = mcp_result.scalars().all()
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„MCPæ’ä»¶
    enable_mcp = any(plugin.enabled for plugin in mcp_plugins) if mcp_plugins else False
    
    if mcp_plugins:
        enabled_count = sum(1 for p in mcp_plugins if p.enabled)
        logger.info(f"ç”¨æˆ· {user.user_id} æœ‰ {len(mcp_plugins)} ä¸ªMCPæ’ä»¶ï¼Œ{enabled_count} ä¸ªå¯ç”¨ï¼Œ{enable_mcp} å†³å®šä½¿ç”¨MCP")
    else:
        logger.debug(f"ç”¨æˆ· {user.user_id} æ²¡æœ‰é…ç½®MCPæ’ä»¶ï¼Œç¦ç”¨MCP")
    
    # âœ… ä½¿ç”¨æ”¯æŒMCPçš„å·¥å‚å‡½æ•°åˆ›å»ºAIæœåŠ¡å®ä¾‹
    # ä¼ é€’ user_id å’Œ db_sessionï¼Œä½¿å¾— AIService èƒ½å¤Ÿè‡ªåŠ¨åŠ è½½ç”¨æˆ·é…ç½®çš„MCPå·¥å…·
    return create_user_ai_service_with_mcp(
        api_provider=settings.api_provider,
        api_key=settings.api_key,
        api_base_url=settings.api_base_url or "",
        model_name=settings.llm_model,
        temperature=settings.temperature,
        max_tokens=settings.max_tokens,
        user_id=user.user_id,          # âœ… ä¼ é€’ user_id
        db_session=db,                 # âœ… ä¼ é€’ db_session
        system_prompt=settings.system_prompt,
        enable_mcp=enable_mcp,         # æ ¹æ®MCPæ’ä»¶çŠ¶æ€åŠ¨æ€å†³å®š
    )


def get_user_ai_service_for_task(task_key: str):
    """ä¾èµ–å·¥å‚ï¼šä¸ºæŒ‡å®š task_key åˆ›å»º AIServiceï¼ˆæ”¯æŒæŒ‰ä»»åŠ¡è·¯ç”±åˆ°ä¸åŒé¢„è®¾ï¼‰ã€‚

    ç”¨æ³•ç¤ºä¾‹ï¼š
        user_ai_service: AIService = Depends(get_user_ai_service_for_task("chapter_generate"))
    """

    async def _dep(
        user: User = Depends(require_login),
        db: AsyncSession = Depends(get_db),
    ) -> AIService:
        return await create_user_ai_service_for_task(
            user_id=user.user_id,
            db=db,
            task_key=task_key,
        )

    return _dep


@router.get("", response_model=SettingsResponse)
async def get_settings(
    user: User = Depends(require_login),
    db: AsyncSession = Depends(get_db)
):
    """
    è·å–å½“å‰ç”¨æˆ·çš„è®¾ç½®
    å¦‚æœç”¨æˆ·æ²¡æœ‰ä¿å­˜è¿‡è®¾ç½®ï¼Œè‡ªåŠ¨ä».envåˆ›å»ºå¹¶ä¿å­˜åˆ°æ•°æ®åº“
    """
    result = await db.execute(
        select(Settings).where(Settings.user_id == user.user_id)
    )
    settings = result.scalar_one_or_none()
    
    if not settings:
        # å¦‚æœç”¨æˆ·æ²¡æœ‰ä¿å­˜è¿‡è®¾ç½®ï¼Œä».envè¯»å–é»˜è®¤é…ç½®å¹¶ä¿å­˜åˆ°æ•°æ®åº“
        env_defaults = read_env_defaults()
        logger.info(f"ç”¨æˆ· {user.user_id} é¦–æ¬¡è·å–è®¾ç½®ï¼Œè‡ªåŠ¨ä».envåŒæ­¥åˆ°æ•°æ®åº“")
        
        # åˆ›å»ºæ–°è®¾ç½®å¹¶ä¿å­˜åˆ°æ•°æ®åº“
        settings = Settings(
            user_id=user.user_id,
            **env_defaults
        )
        db.add(settings)
        await db.commit()
        await db.refresh(settings)
        logger.info(f"ç”¨æˆ· {user.user_id} çš„è®¾ç½®å·²ä».envåŒæ­¥åˆ°æ•°æ®åº“")
    
    logger.info(f"ç”¨æˆ· {user.user_id} è·å–å·²ä¿å­˜çš„è®¾ç½®")
    return settings


@router.post("", response_model=SettingsResponse)
async def save_settings(
    data: SettingsCreate,
    user: User = Depends(require_login),
    db: AsyncSession = Depends(get_db)
):
    """
    åˆ›å»ºæˆ–æ›´æ–°å½“å‰ç”¨æˆ·çš„è®¾ç½®ï¼ˆUpsertï¼‰
    å¦‚æœè®¾ç½®å·²å­˜åœ¨åˆ™æ›´æ–°ï¼Œå¦åˆ™åˆ›å»ºæ–°è®¾ç½®
    ä»…ä¿å­˜åˆ°æ•°æ®åº“
    
    æ³¨æ„ï¼šæ‰‹åŠ¨ä¿å­˜é…ç½®åä¼šè‡ªåŠ¨å–æ¶ˆä¹‹å‰æ¿€æ´»çš„é¢„è®¾çŠ¶æ€ï¼Œ
    å› ä¸ºæ‰‹åŠ¨ä¿®æ”¹çš„é…ç½®å¯èƒ½ä¸é¢„è®¾ä¸ä¸€è‡´
    """
    # æŸ¥æ‰¾ç°æœ‰è®¾ç½®
    result = await db.execute(
        select(Settings).where(Settings.user_id == user.user_id)
    )
    settings = result.scalar_one_or_none()
    
    # å‡†å¤‡æ•°æ®
    settings_dict = data.model_dump(exclude_unset=True)
    
    if settings:
        # æ›´æ–°ç°æœ‰è®¾ç½®
        for key, value in settings_dict.items():
            setattr(settings, key, value)
        
        # æ£€æŸ¥å¹¶å–æ¶ˆé¢„è®¾æ¿€æ´»çŠ¶æ€
        # å› ä¸ºç”¨æˆ·æ‰‹åŠ¨ä¿®æ”¹äº†é…ç½®ï¼Œå¯èƒ½ä¸ä¹‹å‰æ¿€æ´»çš„é¢„è®¾ä¸ä¸€è‡´
        try:
            prefs = json.loads(settings.preferences or '{}')
            api_presets = prefs.get('api_presets', {'presets': [], 'version': '1.0'})
            presets = api_presets.get('presets', [])
            
            # æ‰¾åˆ°æ¿€æ´»çš„é¢„è®¾å¹¶æ£€æŸ¥æ˜¯å¦ä¸å½“å‰ä¿å­˜çš„é…ç½®ä¸€è‡´
            active_preset = next((p for p in presets if p.get('is_active')), None)
            if active_preset:
                preset_config = active_preset.get('config', {})
                # æ£€æŸ¥é…ç½®æ˜¯å¦å‘ç”Ÿå˜åŒ–
                config_changed = (
                    preset_config.get('api_provider') != settings_dict.get('api_provider', settings.api_provider) or
                    preset_config.get('api_key') != settings_dict.get('api_key', settings.api_key) or
                    preset_config.get('api_base_url') != settings_dict.get('api_base_url', settings.api_base_url) or
                    preset_config.get('llm_model') != settings_dict.get('llm_model', settings.llm_model) or
                    preset_config.get('temperature') != settings_dict.get('temperature', settings.temperature) or
                    preset_config.get('max_tokens') != settings_dict.get('max_tokens', settings.max_tokens)
                )
                
                if config_changed:
                    # å–æ¶ˆæ¿€æ´»çŠ¶æ€
                    active_preset['is_active'] = False
                    prefs['api_presets'] = api_presets
                    settings.preferences = json.dumps(prefs, ensure_ascii=False)
                    logger.info(f"ç”¨æˆ· {user.user_id} æ‰‹åŠ¨ä¿®æ”¹é…ç½®ï¼Œå·²å–æ¶ˆé¢„è®¾ {active_preset.get('name')} çš„æ¿€æ´»çŠ¶æ€")
        except (json.JSONDecodeError, TypeError) as e:
            logger.warning(f"è§£æç”¨æˆ· {user.user_id} çš„preferenceså¤±è´¥: {e}")
        
        await db.commit()
        await db.refresh(settings)
        logger.info(f"ç”¨æˆ· {user.user_id} æ›´æ–°è®¾ç½®")
    else:
        # åˆ›å»ºæ–°è®¾ç½®
        settings = Settings(
            user_id=user.user_id,
            **settings_dict
        )
        db.add(settings)
        await db.commit()
        await db.refresh(settings)
        logger.info(f"ç”¨æˆ· {user.user_id} åˆ›å»ºè®¾ç½®")
    
    return settings


@router.put("", response_model=SettingsResponse)
async def update_settings(
    data: SettingsUpdate,
    user: User = Depends(require_login),
    db: AsyncSession = Depends(get_db)
):
    """
    æ›´æ–°å½“å‰ç”¨æˆ·çš„è®¾ç½®
    ä»…ä¿å­˜åˆ°æ•°æ®åº“
    """
    result = await db.execute(
        select(Settings).where(Settings.user_id == user.user_id)
    )
    settings = result.scalar_one_or_none()
    
    if not settings:
        raise HTTPException(status_code=404, detail="è®¾ç½®ä¸å­˜åœ¨ï¼Œè¯·å…ˆåˆ›å»ºè®¾ç½®")
    
    # æ›´æ–°è®¾ç½®
    update_data = data.model_dump(exclude_unset=True)
    for key, value in update_data.items():
        setattr(settings, key, value)
    
    await db.commit()
    await db.refresh(settings)
    logger.info(f"ç”¨æˆ· {user.user_id} æ›´æ–°è®¾ç½®")
    
    return settings


@router.delete("")
async def delete_settings(
    user: User = Depends(require_login),
    db: AsyncSession = Depends(get_db)
):
    """
    åˆ é™¤å½“å‰ç”¨æˆ·çš„è®¾ç½®
    """
    result = await db.execute(
        select(Settings).where(Settings.user_id == user.user_id)
    )
    settings = result.scalar_one_or_none()
    
    if not settings:
        raise HTTPException(status_code=404, detail="è®¾ç½®ä¸å­˜åœ¨")
    
    await db.delete(settings)
    await db.commit()
    logger.info(f"ç”¨æˆ· {user.user_id} åˆ é™¤è®¾ç½®")
    
    return {"message": "è®¾ç½®å·²åˆ é™¤", "user_id": user.user_id}


@router.get("/models")
async def get_available_models(
    api_key: str,
    api_base_url: str,
    provider: str = "openai"
):
    """
    ä»é…ç½®çš„ API è·å–å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨
    
    Args:
        api_key: API å¯†é’¥
        api_base_url: API åŸºç¡€ URL
        provider: API æä¾›å•† (openai, anthropic, azure, custom)
    
    Returns:
        æ¨¡å‹åˆ—è¡¨
    """
    try:
        async with httpx.AsyncClient(timeout=10.0) as client:
            if provider == "openai" or provider == "azure" or provider == "custom":
                # OpenAI å…¼å®¹æ¥å£è·å–æ¨¡å‹åˆ—è¡¨
                url = f"{api_base_url.rstrip('/')}/models"
                headers = {
                    "Authorization": f"Bearer {api_key}",
                    "Content-Type": "application/json"
                }
                
                logger.info(f"æ­£åœ¨ä» {url} è·å–æ¨¡å‹åˆ—è¡¨")
                response = await client.get(url, headers=headers)
                response.raise_for_status()
                
                data = response.json()
                models = []
                
                if "data" in data and isinstance(data["data"], list):
                    for model in data["data"]:
                        model_id = model.get("id", "")
                        # è¿”å›æ‰€æœ‰æ¨¡å‹ï¼Œä¸è¿›è¡Œè¿‡æ»¤
                        if model_id:
                            models.append({
                                "value": model_id,
                                "label": model_id,
                                "description": model.get("description", "") or f"Created: {model.get('created', 'N/A')}"
                            })
                
                if not models:
                    raise HTTPException(
                        status_code=404,
                        detail="æœªèƒ½ä» API è·å–åˆ°å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨"
                    )
                
                logger.info(f"æˆåŠŸè·å– {len(models)} ä¸ªæ¨¡å‹")
                return {
                    "provider": provider,
                    "models": models,
                    "count": len(models)
                }
                
            elif provider == "anthropic":
                # Anthropic models API
                url = f"{api_base_url.rstrip('/')}/v1/models"
                headers = {"x-api-key": api_key, "anthropic-version": "2023-06-01"}
                response = await client.get(url, headers=headers)
                response.raise_for_status()
                data = response.json()
                models = [{"value": m["id"], "label": m["id"], "description": m.get("display_name", "")} for m in data.get("data", [])]
                return {"provider": provider, "models": models, "count": len(models)}
            
            elif provider == "gemini":
                # Gemini models API
                url = f"{api_base_url.rstrip('/')}/models?key={api_key}"
                response = await client.get(url)
                response.raise_for_status()
                data = response.json()
                models = []
                for m in data.get("models", []):
                    if "generateContent" in m.get("supportedGenerationMethods", []):
                        mid = m.get("name", "").replace("models/", "")
                        models.append({"value": mid, "label": m.get("displayName", mid), "description": ""})
                return {"provider": provider, "models": models, "count": len(models)}
            
            else:
                raise HTTPException(status_code=400, detail=f"ä¸æ”¯æŒçš„æä¾›å•†: {provider}")
            
    except httpx.HTTPStatusError as e:
        logger.error(f"è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥ (HTTP {e.response.status_code}): {e.response.text}")
        raise HTTPException(
            status_code=400,
            detail=f"æ— æ³•ä» API è·å–æ¨¡å‹åˆ—è¡¨ (HTTP {e.response.status_code})"
        )
    except httpx.RequestError as e:
        logger.error(f"è¯·æ±‚æ¨¡å‹åˆ—è¡¨å¤±è´¥: {str(e)}")
        raise HTTPException(
            status_code=400,
            detail=f"æ— æ³•è¿æ¥åˆ° API: {str(e)}"
        )
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–æ¨¡å‹åˆ—è¡¨æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: {str(e)}"
        )


class ApiTestRequest(BaseModel):
    """API æµ‹è¯•è¯·æ±‚æ¨¡å‹"""
    api_key: str
    api_base_url: str
    provider: str
    llm_model: str
    temperature: Optional[float] = None
    max_tokens: Optional[int] = None


@router.post("/check-function-calling")
async def check_function_calling_support(data: ApiTestRequest):
    """
    æ£€æŸ¥æ¨¡å‹æ˜¯å¦æ”¯æŒ Function Callingï¼ˆå·¥å…·è°ƒç”¨ï¼‰
    
    åŸºäºä¸šç•Œæœ€ä½³å®è·µçš„æµ‹è¯•æ–¹æ³•ï¼š
    1. å‘é€åŒ…å«å·¥å…·å®šä¹‰çš„è¯·æ±‚
    2. æ£€æŸ¥å“åº”çš„ finish_reason æ˜¯å¦ä¸º "tool_calls"
    3. éªŒè¯å“åº”ä¸­æ˜¯å¦åŒ…å«æœ‰æ•ˆçš„ tool_calls æ•°æ®
    
    Args:
        data: åŒ…å« API é…ç½®çš„è¯·æ±‚æ•°æ®
    
    Returns:
        æ£€æµ‹ç»“æœåŒ…å«æ”¯æŒçŠ¶æ€ã€è¯¦ç»†ä¿¡æ¯å’Œå»ºè®®
    """
    api_key = data.api_key
    api_base_url = data.api_base_url
    provider = data.provider
    llm_model = data.llm_model
    
    try:
        start_time = time.time()
        
        # å®šä¹‰ä¸€ä¸ªç®€å•çš„æµ‹è¯•å·¥å…·ï¼ˆå¤©æ°”æŸ¥è¯¢ï¼‰
        test_tools = [{
            "type": "function",
            "function": {
                "name": "get_weather",
                "description": "è·å–æŒ‡å®šåŸå¸‚çš„å½“å‰å¤©æ°”ä¿¡æ¯",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "city": {
                            "type": "string",
                            "description": "åŸå¸‚åç§°ï¼Œä¾‹å¦‚ï¼šåŒ—äº¬ã€ä¸Šæµ·ã€æ·±åœ³"
                        },
                        "unit": {
                            "type": "string",
                            "enum": ["celsius", "fahrenheit"],
                            "description": "æ¸©åº¦å•ä½"
                        }
                    },
                    "required": ["city"]
                }
            }
        }]
        
        # æµ‹è¯•æç¤ºï¼šæ•…æ„è®¾è®¡ä¸€ä¸ªéœ€è¦è°ƒç”¨å·¥å…·çš„é—®é¢˜
        test_prompt = "è¯·å‘Šè¯‰æˆ‘åŒ—äº¬ç°åœ¨çš„å¤©æ°”æƒ…å†µå¦‚ä½•ï¼Ÿ"
        
        logger.info(f"ğŸ§ª å¼€å§‹æ£€æµ‹ Function Calling æ”¯æŒ")
        logger.info(f"  - æä¾›å•†: {provider}")
        logger.info(f"  - æ¨¡å‹: {llm_model}")
        logger.info(f"  - æµ‹è¯•å·¥å…·: get_weather")
        
        # åˆ›å»ºä¸´æ—¶ AI æœåŠ¡å®ä¾‹è¿›è¡Œæµ‹è¯•
        test_service = AIService(
            api_provider=provider,
            api_key=api_key,
            api_base_url=api_base_url,
            default_model=llm_model,
            default_temperature=0.3,  # ä½¿ç”¨è¾ƒä½æ¸©åº¦ä»¥è·å¾—æ›´ç¡®å®šçš„è¡Œä¸º
            default_max_tokens=200
        )
        
        # å‘é€å¸¦å·¥å…·çš„æµ‹è¯•è¯·æ±‚
        response = await test_service.generate_text(
            prompt=test_prompt,
            provider=provider,
            model=llm_model,
            temperature=0.3,
            max_tokens=200,
            tools=test_tools,
            tool_choice="auto",  # è®©æ¨¡å‹è‡ªåŠ¨å†³å®šæ˜¯å¦ä½¿ç”¨å·¥å…·
            auto_mcp=False  # ç¦ç”¨ MCP è‡ªåŠ¨åŠ è½½
        )
        
        end_time = time.time()
        response_time = round((end_time - start_time) * 1000, 2)
        
        # åˆ†æå“åº”ä»¥ç¡®å®šæ˜¯å¦æ”¯æŒ Function Calling
        supported = False
        finish_reason = None
        tool_calls = None
        response_content = None
        
        if isinstance(response, dict):
            # æ£€æŸ¥ finish_reasonï¼ˆOpenAI æ ‡å‡†ï¼‰
            finish_reason = response.get("finish_reason")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ tool_calls
            if "tool_calls" in response and response["tool_calls"]:
                supported = True
                tool_calls = response["tool_calls"]
                logger.info(f"âœ… æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨: {len(tool_calls)} ä¸ª")
            
            # è®°å½•è¿”å›çš„å†…å®¹ï¼ˆå¦‚æœæœ‰ï¼‰
            if "content" in response:
                response_content = response["content"]
        elif isinstance(response, str):
            # å¦‚æœåªè¿”å›å­—ç¬¦ä¸²ï¼Œè¯´æ˜ä¸æ”¯æŒå·¥å…·è°ƒç”¨
            response_content = response
        
        logger.info(f"  - å“åº”æ—¶é—´: {response_time}ms")
        logger.info(f"  - finish_reason: {finish_reason}")
        logger.info(f"  - æ”¯æŒçŠ¶æ€: {'âœ… æ”¯æŒ' if supported else 'âŒ ä¸æ”¯æŒ'}")
        
        # æ„å»ºè¯¦ç»†çš„è¿”å›ä¿¡æ¯
        result = {
            "success": True,
            "supported": supported,
            "message": "âœ… æ¨¡å‹æ”¯æŒ Function Calling" if supported else "âŒ æ¨¡å‹ä¸æ”¯æŒ Function Calling",
            "response_time_ms": response_time,
            "provider": provider,
            "model": llm_model,
            "details": {
                "finish_reason": finish_reason,
                "has_tool_calls": bool(tool_calls),
                "tool_call_count": len(tool_calls) if tool_calls else 0,
                "test_tool": "get_weather",
                "test_prompt": test_prompt,
                "response_type": "tool_calls" if supported else "text"
            }
        }
        
        # æ·»åŠ å·¥å…·è°ƒç”¨è¯¦æƒ…
        if tool_calls:
            result["tool_calls"] = tool_calls
            result["suggestions"] = [
                "âœ… è¯¥æ¨¡å‹æ”¯æŒ Function Callingï¼Œå¯ä»¥æ­£å¸¸ä½¿ç”¨ MCP æ’ä»¶",
                "å»ºè®®ï¼šå¯ç”¨éœ€è¦çš„ MCP æ’ä»¶ä»¥æ‰©å±• AI èƒ½åŠ›",
                "æç¤ºï¼šæµ‹è¯•æˆåŠŸæ£€æµ‹åˆ°å·¥å…·è°ƒç”¨ï¼Œæ¨¡å‹èƒ½å¤Ÿæ­£ç¡®è§£æå’Œä½¿ç”¨å¤–éƒ¨å·¥å…·"
            ]
        else:
            result["response_preview"] = response_content[:200] if response_content else None
            result["suggestions"] = [
                "âŒ è¯¥æ¨¡å‹ä¸æ”¯æŒ Function Callingï¼Œæ— æ³•ä½¿ç”¨ MCP æ’ä»¶åŠŸèƒ½",
                "å»ºè®®ï¼šæ›´æ¢æ”¯æŒå·¥å…·è°ƒç”¨çš„æ¨¡å‹",
                "æ¨èæ¨¡å‹ï¼šGPT-4 ç³»åˆ—ã€GPT-4-turboã€Claude 3 Opus/Sonnetã€Gemini 1.5 Pro ç­‰",
                "è¯´æ˜ï¼šæ¨¡å‹è¿”å›äº†æ–‡æœ¬å›å¤è€Œéå·¥å…·è°ƒç”¨ï¼Œè¡¨æ˜ä¸æ”¯æŒè¯¥åŠŸèƒ½"
            ]
        
        return result
        
    except ValueError as e:
        error_msg = str(e)
        logger.error(f"âŒ Function Calling æ£€æµ‹é…ç½®é”™è¯¯: {error_msg}")
        return {
            "success": False,
            "supported": False,
            "message": "é…ç½®é”™è¯¯",
            "error": error_msg,
            "error_type": "ConfigurationError",
            "suggestions": [
                "è¯·æ£€æŸ¥ API Key æ˜¯å¦æ­£ç¡®",
                "è¯·ç¡®è®¤ API Base URL æ ¼å¼æ˜¯å¦æ­£ç¡®",
                "è¯·éªŒè¯æ‰€é€‰æä¾›å•†ä¸é…ç½®æ˜¯å¦åŒ¹é…"
            ]
        }
        
    except TimeoutError as e:
        error_msg = str(e)
        logger.error(f"âŒ Function Calling æ£€æµ‹è¶…æ—¶: {error_msg}")
        return {
            "success": False,
            "supported": None,
            "message": "æ£€æµ‹è¶…æ—¶",
            "error": error_msg,
            "error_type": "TimeoutError",
            "suggestions": [
                "è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸",
                "è¯·ç¡®è®¤ API æœåŠ¡æ˜¯å¦å¯è®¿é—®",
                "å»ºè®®ï¼šç¨åé‡è¯•æˆ–ä½¿ç”¨å…¶ä»–ç½‘ç»œç¯å¢ƒ"
            ]
        }
        
    except Exception as e:
        error_msg = str(e)
        error_type = type(e).__name__
        
        logger.error(f"âŒ Function Calling æ£€æµ‹å¤±è´¥: {error_msg}")
        logger.error(f"  - é”™è¯¯ç±»å‹: {error_type}")
        
        # æ™ºèƒ½åˆ†æé”™è¯¯åŸå› 
        suggestions = []
        if "tool" in error_msg.lower() or "function" in error_msg.lower():
            suggestions = [
                "è¯¥æ¨¡å‹å¯èƒ½ä¸æ”¯æŒ Function Calling åŠŸèƒ½",
                "API è¿”å›äº†ä¸å·¥å…·è°ƒç”¨ç›¸å…³çš„é”™è¯¯",
                "å»ºè®®ï¼šæ›´æ¢æ”¯æŒå·¥å…·è°ƒç”¨çš„æ¨¡å‹æˆ–è”ç³» API æä¾›å•†"
            ]
        elif "unauthorized" in error_msg.lower() or "401" in error_msg:
            suggestions = [
                "API Key è®¤è¯å¤±è´¥",
                "è¯·æ£€æŸ¥ API Key æ˜¯å¦æ­£ç¡®ä¸”æœ‰æ•ˆ",
                "è¯·ç¡®è®¤ API Key æ˜¯å¦æœ‰è¶³å¤Ÿçš„æƒé™"
            ]
        elif "not found" in error_msg.lower() or "404" in error_msg:
            suggestions = [
                "æ¨¡å‹ä¸å­˜åœ¨æˆ–ä¸å¯ç”¨",
                "è¯·æ£€æŸ¥æ¨¡å‹åç§°æ˜¯å¦æ­£ç¡®",
                "è¯·ç¡®è®¤è¯¥æ¨¡å‹åœ¨å½“å‰ API ä¸­æ˜¯å¦å¯ç”¨"
            ]
        else:
            suggestions = [
                "æ£€æµ‹è¿‡ç¨‹ä¸­é‡åˆ°æœªçŸ¥é”™è¯¯",
                "å»ºè®®ï¼šæ£€æŸ¥æ‰€æœ‰é…ç½®å‚æ•°æ˜¯å¦æ­£ç¡®",
                "æç¤ºï¼šæŸ¥çœ‹è¯¦ç»†é”™è¯¯ä¿¡æ¯ä»¥è·å–æ›´å¤šçº¿ç´¢"
            ]
        
        return {
            "success": False,
            "supported": False,
            "message": "Function Calling æ£€æµ‹å¤±è´¥",
            "error": error_msg,
            "error_type": error_type,
            "suggestions": suggestions
        }


@router.post("/test")
async def test_api_connection(data: ApiTestRequest):
    """
    æµ‹è¯• API è¿æ¥å’Œé…ç½®æ˜¯å¦æ­£ç¡®
    
    Args:
        data: åŒ…å« API é…ç½®çš„è¯·æ±‚æ•°æ®ï¼ˆåŒ…æ‹¬ temperature å’Œ max_tokensï¼‰
    
    Returns:
        æµ‹è¯•ç»“æœåŒ…å«çŠ¶æ€ã€å“åº”æ—¶é—´å’Œè¯¦ç»†ä¿¡æ¯
    """
    api_key = data.api_key
    api_base_url = data.api_base_url
    provider = data.provider
    llm_model = data.llm_model
    # ä½¿ç”¨å‰ç«¯ä¼ é€’çš„å‚æ•°ï¼Œå¦‚æœæœªä¼ é€’åˆ™ä½¿ç”¨é»˜è®¤å€¼
    temperature = data.temperature if data.temperature is not None else 0.7
    max_tokens = data.max_tokens if data.max_tokens is not None else 2000
    import time
    
    try:
        start_time = time.time()
        
        # åˆ›å»ºä¸´æ—¶ AI æœåŠ¡å®ä¾‹ï¼Œä½¿ç”¨å‰ç«¯ä¼ é€’çš„å‚æ•°
        test_service = AIService(
            api_provider=provider,
            api_key=api_key,
            api_base_url=api_base_url,
            default_model=llm_model,
            default_temperature=temperature,
            default_max_tokens=max_tokens
        )
        
        # å‘é€ç®€å•çš„æµ‹è¯•è¯·æ±‚
        test_prompt = "è¯·ç”¨ä¸€å¥è¯å›å¤ï¼šæµ‹è¯•æˆåŠŸ"
        
        logger.info(f"ğŸ§ª å¼€å§‹æµ‹è¯• API è¿æ¥")
        logger.info(f"  - æä¾›å•†: {provider}")
        logger.info(f"  - æ¨¡å‹: {llm_model}")
        logger.info(f"  - Base URL: {api_base_url}")
        logger.info(f"  - Temperature: {temperature}")
        logger.info(f"  - Max Tokens: {max_tokens}")
        
        response = await test_service.generate_text(
            prompt=test_prompt,
            provider=provider,
            model=llm_model,
            temperature=temperature,
            max_tokens=max_tokens,
            auto_mcp=False  # æµ‹è¯•æ—¶ä¸åŠ è½½MCPå·¥å…·
        )
        
        end_time = time.time()
        response_time = round((end_time - start_time) * 1000, 2)  # è½¬æ¢ä¸ºæ¯«ç§’
        
        logger.info(f"âœ… API æµ‹è¯•æˆåŠŸ")
        logger.info(f"  - å“åº”æ—¶é—´: {response_time}ms")
        
        # å®‰å…¨åœ°å¤„ç†å“åº”å†…å®¹ï¼ˆç¡®ä¿æ˜¯å­—ç¬¦ä¸²ï¼‰
        response_str = str(response) if response else 'N/A'
        logger.info(f"  - å“åº”å†…å®¹: {response_str[:100]}")
        
        return {
            "success": True,
            "message": "API è¿æ¥æµ‹è¯•æˆåŠŸ",
            "response_time_ms": response_time,
            "provider": provider,
            "model": llm_model,
            "response_preview": response_str[:100] if len(response_str) > 100 else response_str,
            "details": {
                "api_available": True,
                "model_accessible": True,
                "response_valid": bool(response),
                "temperature": temperature,
                "max_tokens": max_tokens
            }
        }
        
    except ValueError as e:
        # é…ç½®é”™è¯¯
        error_msg = str(e)
        logger.error(f"âŒ API é…ç½®é”™è¯¯: {error_msg}")
        return {
            "success": False,
            "message": "API é…ç½®é”™è¯¯",
            "error": error_msg,
            "error_type": "ConfigurationError",
            "suggestions": [
                "è¯·æ£€æŸ¥ API Key æ˜¯å¦æ­£ç¡®",
                "è¯·ç¡®è®¤ API Base URL æ ¼å¼æ­£ç¡®",
                "è¯·éªŒè¯æ‰€é€‰æä¾›å•†æ˜¯å¦åŒ¹é…"
            ]
        }
        
    except TimeoutError as e:
        # è¶…æ—¶é”™è¯¯
        error_msg = str(e)
        logger.error(f"âŒ API è¯·æ±‚è¶…æ—¶: {error_msg}")
        return {
            "success": False,
            "message": "API è¯·æ±‚è¶…æ—¶",
            "error": error_msg,
            "error_type": "TimeoutError",
            "suggestions": [
                "è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥",
                "è¯·ç¡®è®¤ API Base URL æ˜¯å¦å¯è®¿é—®",
                "å¦‚æœä½¿ç”¨ä»£ç†ï¼Œè¯·æ£€æŸ¥ä»£ç†è®¾ç½®"
            ]
        }
        
    except Exception as e:
        # å…¶ä»–é”™è¯¯
        error_msg = str(e)
        error_type = type(e).__name__
        
        logger.error(f"âŒ API æµ‹è¯•å¤±è´¥: {error_msg}")
        logger.error(f"  - é”™è¯¯ç±»å‹: {error_type}")
        
        # åˆ†æé”™è¯¯åŸå› å¹¶æä¾›å»ºè®®
        suggestions = []
        if "blocked" in error_msg.lower():
            suggestions = [
                "è¯·æ±‚è¢« API æä¾›å•†é˜»æ­¢",
                "å¯èƒ½åŸå› ï¼šAPI Key è¢«é™åˆ¶æˆ–åœ°åŒºé™åˆ¶",
                "å»ºè®®ï¼šæ£€æŸ¥ API Key çŠ¶æ€å’Œè´¦æˆ·ä½™é¢",
                "å»ºè®®ï¼šå°è¯•æ›´æ¢ API Base URL æˆ–ä½¿ç”¨ä»£ç†"
            ]
        elif "unauthorized" in error_msg.lower() or "401" in error_msg:
            suggestions = [
                "API Key è®¤è¯å¤±è´¥",
                "å»ºè®®ï¼šæ£€æŸ¥ API Key æ˜¯å¦æ­£ç¡®",
                "å»ºè®®ï¼šç¡®è®¤ API Key æ˜¯å¦è¿‡æœŸ"
            ]
        elif "not found" in error_msg.lower() or "404" in error_msg:
            suggestions = [
                "API ç«¯ç‚¹ä¸å­˜åœ¨æˆ–æ¨¡å‹ä¸å¯ç”¨",
                "å»ºè®®ï¼šæ£€æŸ¥ API Base URL æ˜¯å¦æ­£ç¡®",
                "å»ºè®®ï¼šç¡®è®¤æ¨¡å‹åç§°æ˜¯å¦æ­£ç¡®"
            ]
        elif "rate limit" in error_msg.lower() or "429" in error_msg:
            suggestions = [
                "API è¯·æ±‚é¢‘ç‡è¶…é™",
                "å»ºè®®ï¼šç¨åé‡è¯•",
                "å»ºè®®ï¼šå‡çº§ API å¥—é¤"
            ]
        elif "insufficient" in error_msg.lower() or "quota" in error_msg.lower():
            suggestions = [
                "API é…é¢ä¸è¶³",
                "å»ºè®®ï¼šæ£€æŸ¥è´¦æˆ·ä½™é¢",
                "å»ºè®®ï¼šå……å€¼æˆ–å‡çº§å¥—é¤"
            ]
        else:
            suggestions = [
                "è¯·æ£€æŸ¥æ‰€æœ‰é…ç½®å‚æ•°æ˜¯å¦æ­£ç¡®",
                "è¯·ç¡®è®¤ç½‘ç»œè¿æ¥æ­£å¸¸",
                "è¯·æŸ¥çœ‹è¯¦ç»†é”™è¯¯ä¿¡æ¯"
            ]
        
        return {
            "success": False,
            "message": "API æµ‹è¯•å¤±è´¥",
            "error": error_msg,
            "error_type": error_type,
            "suggestions": suggestions
        }


# ========== APIé…ç½®é¢„è®¾ç®¡ç†ï¼ˆé›¶æ•°æ®åº“æ”¹åŠ¨æ–¹æ¡ˆï¼‰==========

async def get_user_settings(user_id: str, db: AsyncSession) -> Settings:
    """è·å–ç”¨æˆ·settingsï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º"""
    result = await db.execute(
        select(Settings).where(Settings.user_id == user_id)
    )
    settings = result.scalar_one_or_none()
    
    if not settings:
        # åˆ›å»ºé»˜è®¤è®¾ç½®
        env_defaults = read_env_defaults()
        settings = Settings(
            user_id=user_id,
            **env_defaults,
            preferences='{}'  # åˆå§‹åŒ–ä¸ºç©ºJSON
        )
        db.add(settings)
        await db.commit()
        await db.refresh(settings)
        logger.info(f"ç”¨æˆ· {user_id} é¦–æ¬¡è®¿é—®ï¼Œå·²åˆ›å»ºé»˜è®¤è®¾ç½®")
    
    return settings


@router.get("/presets", response_model=PresetListResponse)
async def get_presets(
    user: User = Depends(require_login),
    db: AsyncSession = Depends(get_db)
):
    """
    è·å–æ‰€æœ‰APIé…ç½®é¢„è®¾
    
    ä»preferenceså­—æ®µè¯»å–é¢„è®¾åˆ—è¡¨
    """
    settings = await get_user_settings(user.user_id, db)
    
    # è§£æpreferences
    try:
        prefs = json.loads(settings.preferences or '{}')
    except json.JSONDecodeError:
        logger.warning(f"ç”¨æˆ· {user.user_id} çš„preferenceså­—æ®µJSONæ ¼å¼é”™è¯¯ï¼Œé‡ç½®ä¸ºç©º")
        prefs = {}
    
    api_presets = prefs.get('api_presets', {'presets': [], 'version': '1.0'})
    presets = api_presets.get('presets', [])
    
    # æ‰¾åˆ°æ¿€æ´»çš„é¢„è®¾
    active_preset_id = next(
        (p['id'] for p in presets if p.get('is_active')),
        None
    )
    
    logger.info(f"ç”¨æˆ· {user.user_id} è·å–é¢„è®¾åˆ—è¡¨ï¼Œå…± {len(presets)} ä¸ª")
    
    return {
        "presets": presets,
        "total": len(presets),
        "active_preset_id": active_preset_id
    }


@router.post("/presets", response_model=PresetResponse)
async def create_preset(
    data: PresetCreateRequest,
    user: User = Depends(require_login),
    db: AsyncSession = Depends(get_db)
):
    """
    åˆ›å»ºæ–°é¢„è®¾
    
    å°†é¢„è®¾æ·»åŠ åˆ°preferenceså­—æ®µçš„JSONä¸­
    """
    settings = await get_user_settings(user.user_id, db)
    
    # è§£æpreferences
    try:
        prefs = json.loads(settings.preferences or '{}')
    except json.JSONDecodeError:
        prefs = {}
    
    api_presets = prefs.get('api_presets', {'presets': [], 'version': '1.0'})
    presets = api_presets.get('presets', [])
    
    # åˆ›å»ºæ–°é¢„è®¾
    new_preset = {
        "id": f"preset_{int(datetime.now().timestamp() * 1000)}",
        "name": data.name,
        "description": data.description,
        "is_active": False,
        "created_at": datetime.now().isoformat(),
        "config": data.config.model_dump()
    }
    
    presets.append(new_preset)
    
    # ä¿å­˜å›preferences
    api_presets['presets'] = presets
    prefs['api_presets'] = api_presets
    settings.preferences = json.dumps(prefs, ensure_ascii=False)
    
    await db.commit()
    
    logger.info(f"ç”¨æˆ· {user.user_id} åˆ›å»ºé¢„è®¾: {data.name}")
    return new_preset


@router.put("/presets/{preset_id}", response_model=PresetResponse)
async def update_preset(
    preset_id: str,
    data: PresetUpdateRequest,
    user: User = Depends(require_login),
    db: AsyncSession = Depends(get_db)
):
    """
    æ›´æ–°é¢„è®¾
    
    åœ¨preferenceså­—æ®µçš„JSONä¸­æ›´æ–°æŒ‡å®šé¢„è®¾
    """
    settings = await get_user_settings(user.user_id, db)
    
    # è§£æpreferences
    try:
        prefs = json.loads(settings.preferences or '{}')
    except json.JSONDecodeError:
        raise HTTPException(status_code=500, detail="é…ç½®æ•°æ®æ ¼å¼é”™è¯¯")
    
    api_presets = prefs.get('api_presets', {'presets': [], 'version': '1.0'})
    presets = api_presets.get('presets', [])
    
    # æ‰¾åˆ°å¹¶æ›´æ–°é¢„è®¾
    target_preset = next((p for p in presets if p['id'] == preset_id), None)
    if not target_preset:
        raise HTTPException(status_code=404, detail="é¢„è®¾ä¸å­˜åœ¨")
    
    # æ›´æ–°å­—æ®µ
    if data.name is not None:
        target_preset['name'] = data.name
    if data.description is not None:
        target_preset['description'] = data.description
    if data.config is not None:
        target_preset['config'] = data.config.model_dump()
    
    # ä¿å­˜å›preferences
    prefs['api_presets'] = api_presets
    settings.preferences = json.dumps(prefs, ensure_ascii=False)
    
    await db.commit()
    
    logger.info(f"ç”¨æˆ· {user.user_id} æ›´æ–°é¢„è®¾: {preset_id}")
    return target_preset


@router.delete("/presets/{preset_id}")
async def delete_preset(
    preset_id: str,
    user: User = Depends(require_login),
    db: AsyncSession = Depends(get_db)
):
    """
    åˆ é™¤é¢„è®¾
    
    ä»preferenceså­—æ®µçš„JSONä¸­åˆ é™¤æŒ‡å®šé¢„è®¾
    """
    settings = await get_user_settings(user.user_id, db)
    
    # è§£æpreferences
    try:
        prefs = json.loads(settings.preferences or '{}')
    except json.JSONDecodeError:
        raise HTTPException(status_code=500, detail="é…ç½®æ•°æ®æ ¼å¼é”™è¯¯")
    
    api_presets = prefs.get('api_presets', {'presets': [], 'version': '1.0'})
    presets = api_presets.get('presets', [])
    
    # æ‰¾åˆ°é¢„è®¾
    target_preset = next((p for p in presets if p['id'] == preset_id), None)
    if not target_preset:
        raise HTTPException(status_code=404, detail="é¢„è®¾ä¸å­˜åœ¨")
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯æ¿€æ´»çš„é¢„è®¾
    if target_preset.get('is_active'):
        raise HTTPException(status_code=400, detail="æ— æ³•åˆ é™¤æ¿€æ´»ä¸­çš„é¢„è®¾ï¼Œè¯·å…ˆæ¿€æ´»å…¶ä»–é¢„è®¾")
    
    # åˆ é™¤é¢„è®¾
    presets = [p for p in presets if p['id'] != preset_id]
    
    # ä¿å­˜å›preferences
    api_presets['presets'] = presets
    prefs['api_presets'] = api_presets
    settings.preferences = json.dumps(prefs, ensure_ascii=False)
    
    await db.commit()
    
    logger.info(f"ç”¨æˆ· {user.user_id} åˆ é™¤é¢„è®¾: {preset_id}")
    return {"message": "é¢„è®¾å·²åˆ é™¤", "preset_id": preset_id}


@router.post("/presets/{preset_id}/activate")
async def activate_preset(
    preset_id: str,
    user: User = Depends(require_login),
    db: AsyncSession = Depends(get_db)
):
    """
    æ¿€æ´»é¢„è®¾
    
    å°†é¢„è®¾çš„é…ç½®åº”ç”¨åˆ°Settingsä¸»å­—æ®µ
    """
    settings = await get_user_settings(user.user_id, db)
    
    # è§£æpreferences
    try:
        prefs = json.loads(settings.preferences or '{}')
    except json.JSONDecodeError:
        raise HTTPException(status_code=500, detail="é…ç½®æ•°æ®æ ¼å¼é”™è¯¯")
    
    api_presets = prefs.get('api_presets', {'presets': [], 'version': '1.0'})
    presets = api_presets.get('presets', [])
    
    # æ‰¾åˆ°ç›®æ ‡é¢„è®¾
    target_preset = next((p for p in presets if p['id'] == preset_id), None)
    if not target_preset:
        raise HTTPException(status_code=404, detail="é¢„è®¾ä¸å­˜åœ¨")
    
    # åº”ç”¨é…ç½®åˆ°Settingsä¸»å­—æ®µ
    config = target_preset['config']
    settings.api_provider = config['api_provider']
    settings.api_key = config['api_key']
    settings.api_base_url = config.get('api_base_url')
    settings.llm_model = config['llm_model']
    settings.temperature = config['temperature']
    settings.max_tokens = config['max_tokens']
    
    # æ›´æ–°æ‰€æœ‰é¢„è®¾çš„is_activeçŠ¶æ€
    for preset in presets:
        preset['is_active'] = (preset['id'] == preset_id)
    
    # ä¿å­˜å›preferences
    prefs['api_presets'] = api_presets
    settings.preferences = json.dumps(prefs, ensure_ascii=False)
    
    await db.commit()
    
    logger.info(f"ç”¨æˆ· {user.user_id} æ¿€æ´»é¢„è®¾: {target_preset['name']}")
    return {
        "message": "é¢„è®¾å·²æ¿€æ´»",
        "preset_id": preset_id,
        "preset_name": target_preset['name']
    }


@router.get("/ai-routes", response_model=AIRoutesResponse)
async def get_ai_routes(
    user: User = Depends(require_login),
    db: AsyncSession = Depends(get_db),
):
    """è·å– AI ä»»åŠ¡è·¯ç”±é…ç½®ï¼ˆtask_key -> preset_idï¼‰ã€‚"""
    settings = await get_user_settings(user.user_id, db)
    prefs = _safe_load_preferences(settings.preferences)
    routes = _get_ai_routes_from_preferences(prefs)

    # ç¡®ä¿æ‰€æœ‰å·²å®šä¹‰ task_key éƒ½è¿”å›ï¼ˆæœªé…ç½®åˆ™ Noneï¼‰
    full_routes: Dict[str, Optional[str]] = {
        item["key"]: routes.get(item["key"])
        for item in AI_ROUTE_TASKS
    }

    return AIRoutesResponse(
        version=AI_ROUTE_VERSION,
        routes=full_routes,
        tasks=[AIRouteTask(**item) for item in AI_ROUTE_TASKS],
    )


@router.put("/ai-routes", response_model=AIRoutesResponse)
async def update_ai_routes(
    data: AIRoutesUpdateRequest,
    user: User = Depends(require_login),
    db: AsyncSession = Depends(get_db),
):
    """æ›´æ–° AI ä»»åŠ¡è·¯ç”±é…ç½®ã€‚

    - routes çš„ value ä¸º preset_id æˆ– Noneï¼ˆNone è¡¨ç¤ºä½¿ç”¨å½“å‰é…ç½®ï¼‰
    - preset_id å¿…é¡»å­˜åœ¨äºç”¨æˆ·çš„ api_presets ä¸­
    """
    settings = await get_user_settings(user.user_id, db)
    prefs = _safe_load_preferences(settings.preferences)

    # æ ¡éªŒ preset_id æ˜¯å¦å­˜åœ¨
    presets = _get_presets_from_preferences(prefs)
    preset_ids = {str(p.get("id")) for p in presets if p.get("id")}

    for task_key, preset_id in (data.routes or {}).items():
        if preset_id is None:
            continue
        if not isinstance(preset_id, str) or not preset_id.strip():
            continue
        if preset_id not in preset_ids:
            raise HTTPException(status_code=400, detail=f"è·¯ç”±é…ç½®å¼•ç”¨äº†ä¸å­˜åœ¨çš„é¢„è®¾: {preset_id} (task={task_key})")

    # åªä¿å­˜å·²å®šä¹‰ä»»åŠ¡çš„é…ç½®ï¼ˆå¿½ç•¥æœªçŸ¥ keyï¼Œé¿å…å‰åç«¯ç‰ˆæœ¬å·®å¼‚é€ æˆæ±¡æŸ“ï¼‰
    normalized_routes: Dict[str, Optional[str]] = {}
    for item in AI_ROUTE_TASKS:
        key = item["key"]
        val = (data.routes or {}).get(key)
        if isinstance(val, str) and val.strip():
            normalized_routes[key] = val.strip()
        else:
            normalized_routes[key] = None

    prefs = _upsert_ai_routes_to_preferences(prefs, normalized_routes)
    settings.preferences = json.dumps(prefs, ensure_ascii=False)
    await db.commit()

    return AIRoutesResponse(
        version=AI_ROUTE_VERSION,
        routes=normalized_routes,
        tasks=[AIRouteTask(**item) for item in AI_ROUTE_TASKS],
    )


@router.get("/retrieval", response_model=RetrievalConfigResponse)
async def get_retrieval_config(
    user: User = Depends(require_login),
    db: AsyncSession = Depends(get_db),
):
    """è·å–å‘é‡æ£€ç´¢é…ç½®ï¼ˆEmbedding / Rerankï¼‰ã€‚"""
    settings = await get_user_settings(user.user_id, db)
    prefs = _safe_load_preferences(settings.preferences)
    raw = _get_retrieval_from_preferences(prefs)
    try:
        return RetrievalConfigResponse(**raw)
    except Exception:
        # é…ç½®æŸåæ—¶å›é€€åˆ°é»˜è®¤
        return RetrievalConfigResponse()


@router.put("/retrieval", response_model=RetrievalConfigResponse)
async def update_retrieval_config(
    data: RetrievalConfigUpdateRequest,
    user: User = Depends(require_login),
    db: AsyncSession = Depends(get_db),
):
    """æ›´æ–°å‘é‡æ£€ç´¢é…ç½®ï¼ˆEmbedding / Rerankï¼‰ã€‚"""
    settings = await get_user_settings(user.user_id, db)
    prefs = _safe_load_preferences(settings.preferences)

    cfg = RetrievalConfigResponse(
        version=RETRIEVAL_CONFIG_VERSION,
        embedding=data.embedding,
        rerank=data.rerank,
    )

    prefs = _upsert_retrieval_to_preferences(prefs, cfg.model_dump())
    settings.preferences = json.dumps(prefs, ensure_ascii=False)
    await db.commit()

    # è¿”å›å†™å…¥åçš„æœ€ç»ˆå€¼ï¼ˆå¸¦é»˜è®¤è¡¥é½ï¼‰
    raw = _get_retrieval_from_preferences(prefs)
    try:
        return RetrievalConfigResponse(**raw)
    except Exception:
        return RetrievalConfigResponse()




@router.post("/retrieval/test-embedding", response_model=EmbeddingTestResponse)
async def test_embedding_config(
    data: EmbeddingTestRequest,
    user: User = Depends(require_login),
    db: AsyncSession = Depends(get_db),
):
    """æ£€æµ‹ Embedding é…ç½®æ˜¯å¦å¯ç”¨ï¼ˆç”¨äºå‰ç«¯ Settings æ£€æµ‹æŒ‰é’®ï¼‰ã€‚

    - backend=localï¼šæ£€æŸ¥æœ¬åœ° sentence-transformers æ¨¡å‹æ˜¯å¦å·²åŠ è½½
    - backend=remoteï¼šè°ƒç”¨ OpenAI å…¼å®¹ /v1/embeddings åšä¸€æ¬¡æœ€å°è¯·æ±‚å¹¶æ ¡éªŒè¿”å›æ ¼å¼

    æ³¨æ„ï¼šè¯¥æ¥å£ä¸å†™å…¥ settings.preferencesï¼Œä»…ç”¨äºæ£€æµ‹ã€‚
    """
    from app.services.memory_service import memory_service

    settings = await get_user_settings(user.user_id, db)

    embedding = data.embedding
    backend = str(getattr(embedding, "backend", None) or "local").lower()

    if backend != "remote":
        ok = getattr(memory_service, "embedding_model", None) is not None
        if ok:
            return EmbeddingTestResponse(
                success=True,
                backend="local",
                message="æœ¬åœ° Embedding æ¨¡å‹å·²åŠ è½½ï¼Œå¯æ­£å¸¸ä½¿ç”¨",
                details={
                    "model_loaded": True,
                    "hint": "å½“å‰ä¸ºæœ¬åœ° embeddingã€‚è‹¥æƒ³é¿å…æœ¬åœ°æ¨¡å‹ä½“ç§¯/ä¾èµ–ï¼Œå¯åˆ‡æ¢åˆ°è¿œç«¯ embeddingã€‚",
                },
            )
        return EmbeddingTestResponse(
            success=False,
            backend="local",
            message="æœ¬åœ° Embedding æ¨¡å‹æœªåŠ è½½ï¼ˆå°†å¯¼è‡´è®°å¿†æ£€ç´¢å¤±è´¥ï¼‰",
            error="Local embedding model not loaded",
            error_type="LocalEmbeddingNotLoaded",
            suggestions=[
                "è¯·ç¡®è®¤ embedding æ¨¡å‹æ–‡ä»¶å·²å­˜åœ¨ï¼ˆä¾‹å¦‚ paraphrase-multilingual-MiniLM-L12-v2ï¼‰",
                "å¦‚æœä½ ä½¿ç”¨çš„æ˜¯ Docker é•œåƒç‰ˆæœ¬ï¼šè¯·ç¡®è®¤é•œåƒå†…å·²åŒ…å« embedding æ¨¡å‹æ–‡ä»¶ï¼Œæˆ–æŒ‰é¡¹ç›®è¯´æ˜ä¸‹è½½æ¨¡å‹",
                "ä¹Ÿå¯ä»¥åœ¨è®¾ç½®ä¸­å°† Embedding åç«¯åˆ‡æ¢ä¸ºã€Œè¿œç«¯ï¼ˆOpenAI å…¼å®¹ /v1/embeddingsï¼‰ã€",
            ],
        )

    remote = embedding.remote
    provider = str(getattr(remote, "provider", None) or "openai_compatible")
    model = getattr(remote, "model", None) or None

    # å…è®¸ç•™ç©ºå¤ç”¨å½“å‰ LLM é…ç½®ï¼ˆä¸ MemoryService è¡Œä¸ºä¿æŒä¸€è‡´ï¼‰
    api_base_url = getattr(remote, "api_base_url", None) or (settings.api_base_url if settings else None)
    api_key = getattr(remote, "api_key", None) or (settings.api_key if settings else None) or ""
    timeout_s = int(getattr(remote, "timeout_s", None) or 60)

    used_fallback_base_url = not bool(getattr(remote, "api_base_url", None))
    used_fallback_api_key = not bool(getattr(remote, "api_key", None))

    if not api_base_url or not model:
        return EmbeddingTestResponse(
            success=False,
            backend="remote",
            message="è¿œç«¯ Embedding é…ç½®ä¸å®Œæ•´",
            error="api_base_url / model ä¸èƒ½ä¸ºç©ºï¼ˆapi_base_url å…è®¸ç•™ç©ºå¤ç”¨å½“å‰é…ç½®ï¼Œä½†å½“å‰é…ç½®ä¹Ÿä¸ºç©ºï¼‰",
            error_type="ConfigurationError",
            suggestions=[
                "è¯·å¡«å†™ Embedding æ¨¡å‹åç§°ï¼ˆmodelï¼‰",
                "è¯·å¡«å†™ Embedding API åœ°å€ï¼ˆapi_base_urlï¼‰ï¼Œæˆ–å…ˆåœ¨ã€Œå½“å‰é…ç½®ã€ä¸­å¡«å†™ API åœ°å€ä»¥ä¾›å¤ç”¨",
            ],
        )

    if provider != "openai_compatible":
        provider = "openai_compatible"

    url = memory_service._build_openai_compatible_url(str(api_base_url), "embeddings")
    headers: Dict[str, str] = {"Content-Type": "application/json"}
    if api_key:
        headers["Authorization"] = f"Bearer {api_key}"

    payload = {"model": model, "input": ["ä½ å¥½ï¼ŒEmbedding æµ‹è¯•"], "encoding_format": "float"}

    start = time.time()
    try:
        async with httpx.AsyncClient(timeout=timeout_s) as client:
            resp = await client.post(url, headers=headers, json=payload)
            resp.raise_for_status()
            data_json = resp.json()

        cost_ms = round((time.time() - start) * 1000, 2)

        items = data_json.get("data") or []
        if not isinstance(items, list) or not items:
            raise ValueError("è¿”å›ç¼ºå°‘ data æ•°ç»„æˆ– data ä¸ºç©º")

        first = items[0] if isinstance(items[0], dict) else None
        if not first:
            raise ValueError("è¿”å› data[0] ä¸æ˜¯å¯¹è±¡")

        emb = first.get("embedding")
        if not isinstance(emb, list) or not emb:
            raise ValueError("è¿”å› data[0].embedding ä¸æ˜¯éç©º list")

        try:
            _ = float(emb[0])
        except Exception:
            raise ValueError("è¿”å› embedding ä¸æ˜¯æ•°å€¼åˆ—è¡¨")

        return EmbeddingTestResponse(
            success=True,
            backend="remote",
            message="è¿œç«¯ Embedding æ£€æµ‹é€šè¿‡",
            response_time_ms=cost_ms,
            details={
                "api_base_url": api_base_url,
                "endpoint": url,
                "model": model,
                "vector_dim": len(emb),
                "preview": emb[:8],
                "used_fallback": {
                    "api_base_url": used_fallback_base_url,
                    "api_key": used_fallback_api_key,
                },
            },
        )

    except httpx.HTTPStatusError as e:
        status = e.response.status_code if e.response else None
        raw = ""
        try:
            raw = e.response.text if e.response else ""
        except Exception:
            raw = ""

        suggestions: list[str] = []
        if status in (401, 403):
            suggestions = ["API Key è®¤è¯å¤±è´¥ï¼šè¯·æ£€æŸ¥ Embedding API Key æ˜¯å¦æ­£ç¡®/æœ‰æƒé™ã€‚"]
        elif status == 404:
            suggestions = ["æ¥å£æˆ–æ¨¡å‹ä¸å­˜åœ¨ï¼šè¯·æ£€æŸ¥ api_base_url æ˜¯å¦åŒ…å« /v1ï¼Œä»¥åŠ model åç§°æ˜¯å¦æ­£ç¡®ã€‚"]
        elif status == 400:
            suggestions = [
                "è¯·æ±‚å‚æ•°ä¸ç¬¦åˆè¯¥æœåŠ¡çš„ embeddings æ¥å£è¦æ±‚ã€‚",
                "å»ºè®®æ£€æŸ¥ï¼šmodel åç§°ã€æ˜¯å¦éœ€è¦ encoding_formatã€input æ˜¯å¦æ”¯æŒæ•°ç»„ã€‚",
            ]
        elif status == 429:
            suggestions = ["è§¦å‘é™æµï¼ˆ429ï¼‰ï¼šè¯·é™ä½å¹¶å‘/é¢‘ç‡æˆ–ç¨åé‡è¯•ï¼Œæˆ–æ›´æ¢é¢åº¦æ›´é«˜çš„æœåŠ¡ã€‚"]
        else:
            suggestions = ["æœåŠ¡ç«¯è¿”å›é”™è¯¯ï¼šè¯·æŸ¥çœ‹é”™è¯¯è¯¦æƒ…æˆ–ç¨åé‡è¯•ã€‚"]

        return EmbeddingTestResponse(
            success=False,
            backend="remote",
            message="è¿œç«¯ Embedding æ£€æµ‹å¤±è´¥",
            error=f"HTTP {status}: {raw[:500]}",
            error_type="HTTPStatusError",
            suggestions=suggestions,
        )

    except httpx.RequestError as e:
        return EmbeddingTestResponse(
            success=False,
            backend="remote",
            message="è¿œç«¯ Embedding æ£€æµ‹å¤±è´¥ï¼ˆç½‘ç»œ/è¿æ¥é”™è¯¯ï¼‰",
            error=str(e),
            error_type="RequestError",
            suggestions=[
                "è¯·æ£€æŸ¥ç½‘ç»œæ˜¯å¦å¯è¾¾è¯¥ Embedding æœåŠ¡",
                "è¯·æ£€æŸ¥ api_base_url æ˜¯å¦æ­£ç¡®ï¼ˆæ˜¯å¦éœ€è¦èµ°ä»£ç†ï¼‰",
                "è‹¥æ˜¯è‡ªå»ºæœåŠ¡ï¼šç¡®è®¤ç«¯å£ã€TLSã€åŸŸåè§£ææ­£å¸¸",
            ],
        )

    except Exception as e:
        return EmbeddingTestResponse(
            success=False,
            backend="remote",
            message="è¿œç«¯ Embedding æ£€æµ‹å¤±è´¥ï¼ˆæœªçŸ¥é”™è¯¯ï¼‰",
            error=str(e),
            error_type=type(e).__name__,
            suggestions=["è¯·æ£€æŸ¥é…ç½®æ˜¯å¦æ­£ç¡®ï¼Œæˆ–æŸ¥çœ‹åç«¯æ—¥å¿— app.log è·å–æ›´å¤šä¿¡æ¯ã€‚"],
        )


@router.post("/retrieval/test-rerank", response_model=RerankTestResponse)
async def test_rerank_config(
    data: RerankTestRequest,
    user: User = Depends(require_login),
    db: AsyncSession = Depends(get_db),
):
    """æ£€æµ‹ Rerank é…ç½®æ˜¯å¦å¯ç”¨ï¼ˆç”¨äºå‰ç«¯ Settings æ£€æµ‹æŒ‰é’®ï¼‰ã€‚

    - enabled=falseï¼šç›´æ¥è¿”å›æç¤ºï¼ˆä¸æŠ¥é”™ï¼‰
    - enabled=trueï¼šè°ƒç”¨ Cohere å…¼å®¹ /v1/rerank åšä¸€æ¬¡æœ€å°è¯·æ±‚å¹¶æ ¡éªŒè¿”å›æ ¼å¼

    æ³¨æ„ï¼šè¯¥æ¥å£ä¸å†™å…¥ settings.preferencesï¼Œä»…ç”¨äºæ£€æµ‹ã€‚
    """
    from app.services.memory_service import memory_service

    settings = await get_user_settings(user.user_id, db)

    rerank = data.rerank
    enabled = bool(getattr(rerank, "enabled", False))
    if not enabled:
        return RerankTestResponse(
            success=True,
            enabled=False,
            message="Rerank æœªå¯ç”¨ï¼Œæ— éœ€æ£€æµ‹",
            details={"enabled": False},
        )

    remote = rerank.remote
    provider = str(getattr(remote, "provider", None) or "cohere_compatible")
    model = getattr(remote, "model", None) or None
    api_base_url = getattr(remote, "api_base_url", None) or (settings.api_base_url if settings else None)
    api_key = getattr(remote, "api_key", None) or (settings.api_key if settings else None) or ""
    timeout_s = int(getattr(remote, "timeout_s", None) or 60)
    top_n_cfg = int(getattr(remote, "top_n", None) or 10)

    used_fallback_base_url = not bool(getattr(remote, "api_base_url", None))
    used_fallback_api_key = not bool(getattr(remote, "api_key", None))

    if not api_base_url or not model:
        return RerankTestResponse(
            success=False,
            enabled=True,
            message="è¿œç«¯ Rerank é…ç½®ä¸å®Œæ•´",
            error="api_base_url / model ä¸èƒ½ä¸ºç©ºï¼ˆapi_base_url å…è®¸ç•™ç©ºå¤ç”¨å½“å‰é…ç½®ï¼Œä½†å½“å‰é…ç½®ä¹Ÿä¸ºç©ºï¼‰",
            error_type="ConfigurationError",
            suggestions=[
                "è¯·å¡«å†™ Rerank æ¨¡å‹åç§°ï¼ˆmodelï¼‰",
                "è¯·å¡«å†™ Rerank API åœ°å€ï¼ˆapi_base_urlï¼‰ï¼Œæˆ–å…ˆåœ¨ã€Œå½“å‰é…ç½®ã€ä¸­å¡«å†™ API åœ°å€ä»¥ä¾›å¤ç”¨",
            ],
        )

    if provider != "cohere_compatible":
        provider = "cohere_compatible"

    url = memory_service._build_openai_compatible_url(str(api_base_url), "rerank")
    headers: Dict[str, str] = {"Content-Type": "application/json"}
    if api_key:
        headers["Authorization"] = f"Bearer {api_key}"

    query = "å¦‚ä½•åœ¨2005å¹´çš„ç”µè„‘ä¸Šæå‡ç¨‹åºè¿è¡Œé€Ÿåº¦ï¼Ÿ"
    documents = [
        "ç»™å†…å­˜åŠ åˆ°512MBä»¥ä¸Šï¼Œå…³é—­åå°ç¨‹åºï¼Œå‡å°‘ç£ç›˜ç¢ç‰‡ã€‚",
        "ä¹°ä¸€å°æ›´å¥½çš„æ˜¾å¡å¯ä»¥è®©æ‰“å­—æ›´å¿«ã€‚",
        "é™ä½ç®—æ³•å¤æ‚åº¦ï¼Œé¿å…ä¸å¿…è¦çš„IOï¼Œä½¿ç”¨ç¼“å­˜ã€‚",
    ]
    top_n = max(1, min(top_n_cfg, len(documents)))

    payload = {"model": model, "query": query, "documents": documents, "top_n": top_n}

    start = time.time()
    try:
        async with httpx.AsyncClient(timeout=timeout_s) as client:
            resp = await client.post(url, headers=headers, json=payload)
            resp.raise_for_status()
            data_json = resp.json()

        cost_ms = round((time.time() - start) * 1000, 2)

        results = data_json.get("results") or data_json.get("data") or []
        if not isinstance(results, list) or not results:
            raise ValueError("è¿”å›ç¼ºå°‘ results æ•°ç»„æˆ– results ä¸ºç©º")

        parsed: list[dict[str, Any]] = []
        for r in results[: min(5, len(results))]:
            if not isinstance(r, dict):
                continue
            idx = r.get("index")
            score = r.get("relevance_score", r.get("score"))
            try:
                idx_i = int(idx)
            except Exception:
                continue
            try:
                score_f = float(score) if score is not None else None
            except Exception:
                score_f = None
            parsed.append({"index": idx_i, "score": score_f})

        if not parsed:
            raise ValueError("results è§£æå¤±è´¥ï¼šç¼ºå°‘ index / relevance_score")

        return RerankTestResponse(
            success=True,
            enabled=True,
            message="è¿œç«¯ Rerank æ£€æµ‹é€šè¿‡",
            response_time_ms=cost_ms,
            details={
                "api_base_url": api_base_url,
                "endpoint": url,
                "model": model,
                "top_n": top_n,
                "sample_query": query,
                "sample_docs_count": len(documents),
                "top_results_preview": parsed,
                "used_fallback": {
                    "api_base_url": used_fallback_base_url,
                    "api_key": used_fallback_api_key,
                },
            },
        )

    except httpx.HTTPStatusError as e:
        status = e.response.status_code if e.response else None
        raw = ""
        try:
            raw = e.response.text if e.response else ""
        except Exception:
            raw = ""

        suggestions: list[str] = []
        if status in (401, 403):
            suggestions = ["API Key è®¤è¯å¤±è´¥ï¼šè¯·æ£€æŸ¥ Rerank API Key æ˜¯å¦æ­£ç¡®/æœ‰æƒé™ã€‚"]
        elif status == 404:
            suggestions = ["æ¥å£æˆ–æ¨¡å‹ä¸å­˜åœ¨ï¼šè¯·æ£€æŸ¥ api_base_url æ˜¯å¦åŒ…å« /v1ï¼Œä»¥åŠ model åç§°æ˜¯å¦æ­£ç¡®ã€‚"]
        elif status == 400:
            suggestions = [
                "è¯·æ±‚å‚æ•°ä¸ç¬¦åˆè¯¥æœåŠ¡çš„ rerank æ¥å£è¦æ±‚ã€‚",
                "å»ºè®®æ£€æŸ¥ï¼šmodel åç§°ã€top_n æ˜¯å¦åˆç†ã€documents æ˜¯å¦ä¸ºå­—ç¬¦ä¸²æ•°ç»„ã€‚",
            ]
        elif status == 429:
            suggestions = ["è§¦å‘é™æµï¼ˆ429ï¼‰ï¼šè¯·é™ä½å¹¶å‘/é¢‘ç‡æˆ–ç¨åé‡è¯•ï¼Œæˆ–æ›´æ¢é¢åº¦æ›´é«˜çš„æœåŠ¡ã€‚"]
        else:
            suggestions = ["æœåŠ¡ç«¯è¿”å›é”™è¯¯ï¼šè¯·æŸ¥çœ‹é”™è¯¯è¯¦æƒ…æˆ–ç¨åé‡è¯•ã€‚"]

        return RerankTestResponse(
            success=False,
            enabled=True,
            message="è¿œç«¯ Rerank æ£€æµ‹å¤±è´¥",
            error=f"HTTP {status}: {raw[:500]}",
            error_type="HTTPStatusError",
            suggestions=suggestions,
        )

    except httpx.RequestError as e:
        return RerankTestResponse(
            success=False,
            enabled=True,
            message="è¿œç«¯ Rerank æ£€æµ‹å¤±è´¥ï¼ˆç½‘ç»œ/è¿æ¥é”™è¯¯ï¼‰",
            error=str(e),
            error_type="RequestError",
            suggestions=[
                "è¯·æ£€æŸ¥ç½‘ç»œæ˜¯å¦å¯è¾¾è¯¥ Rerank æœåŠ¡",
                "è¯·æ£€æŸ¥ api_base_url æ˜¯å¦æ­£ç¡®ï¼ˆæ˜¯å¦éœ€è¦èµ°ä»£ç†ï¼‰",
                "è‹¥æ˜¯è‡ªå»ºæœåŠ¡ï¼šç¡®è®¤ç«¯å£ã€TLSã€åŸŸåè§£ææ­£å¸¸",
            ],
        )

    except Exception as e:
        return RerankTestResponse(
            success=False,
            enabled=True,
            message="è¿œç«¯ Rerank æ£€æµ‹å¤±è´¥ï¼ˆæœªçŸ¥é”™è¯¯ï¼‰",
            error=str(e),
            error_type=type(e).__name__,
            suggestions=["è¯·æ£€æŸ¥é…ç½®æ˜¯å¦æ­£ç¡®ï¼Œæˆ–æŸ¥çœ‹åç«¯æ—¥å¿— app.log è·å–æ›´å¤šä¿¡æ¯ã€‚"],
        )
@router.post("/presets/{preset_id}/test")
async def test_preset(
    preset_id: str,
    user: User = Depends(require_login),
    db: AsyncSession = Depends(get_db)
):
    """
    æµ‹è¯•é¢„è®¾çš„APIè¿æ¥
    """
    settings = await get_user_settings(user.user_id, db)
    
    # è§£æpreferences
    try:
        prefs = json.loads(settings.preferences or '{}')
    except json.JSONDecodeError:
        raise HTTPException(status_code=500, detail="é…ç½®æ•°æ®æ ¼å¼é”™è¯¯")
    
    api_presets = prefs.get('api_presets', {'presets': [], 'version': '1.0'})
    presets = api_presets.get('presets', [])
    
    # æ‰¾åˆ°é¢„è®¾
    target_preset = next((p for p in presets if p['id'] == preset_id), None)
    if not target_preset:
        raise HTTPException(status_code=404, detail="é¢„è®¾ä¸å­˜åœ¨")
    
    # ä½¿ç”¨ç°æœ‰çš„test_api_connectioné€»è¾‘
    # ç¡®ä¿ä¼ é€’å®Œæ•´å‚æ•°ï¼Œä¸å½“å‰é…ç½®æµ‹è¯•ä¿æŒä¸€è‡´
    config = target_preset['config']
    test_request = ApiTestRequest(
        api_key=config['api_key'],
        api_base_url=config.get('api_base_url', ''),
        provider=config['api_provider'],
        llm_model=config['llm_model'],
        temperature=config.get('temperature'),   # ä½¿ç”¨é¢„è®¾ä¸­çš„æ¸©åº¦å‚æ•°
        max_tokens=config.get('max_tokens')      # ä½¿ç”¨é¢„è®¾ä¸­çš„æœ€å¤§tokenså‚æ•°
    )
    
    logger.info(f"ç”¨æˆ· {user.user_id} æµ‹è¯•é¢„è®¾: {target_preset['name']}")
    return await test_api_connection(test_request)


@router.post("/presets/from-current", response_model=PresetResponse)
async def create_preset_from_current(
    name: str,
    description: Optional[str] = None,
    user: User = Depends(require_login),
    db: AsyncSession = Depends(get_db)
):
    """
    ä»å½“å‰é…ç½®åˆ›å»ºæ–°é¢„è®¾
    
    å¿«æ·æ–¹å¼ï¼šå°†å½“å‰æ¿€æ´»çš„é…ç½®ä¿å­˜ä¸ºæ–°é¢„è®¾
    """
    settings = await get_user_settings(user.user_id, db)
    
    # ä»å½“å‰Settingsä¸»å­—æ®µè¯»å–é…ç½®
    current_config = APIKeyPresetConfig(
        api_provider=settings.api_provider,
        api_key=settings.api_key,
        api_base_url=settings.api_base_url,
        llm_model=settings.llm_model,
        temperature=settings.temperature,
        max_tokens=settings.max_tokens
    )
    
    # åˆ›å»ºé¢„è®¾
    create_request = PresetCreateRequest(
        name=name,
        description=description,
        config=current_config
    )
    
    logger.info(f"ç”¨æˆ· {user.user_id} ä»å½“å‰é…ç½®åˆ›å»ºé¢„è®¾: {name}")
    return await create_preset(create_request, user, db)
